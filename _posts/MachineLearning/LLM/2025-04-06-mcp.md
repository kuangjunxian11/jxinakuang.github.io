---

layout: post
title: mcp学习
category: 技术
tags: MachineLearning
keywords: mcp

---

* TOC
{:toc}

## 简介（未完成）

MCP 的主要目的是标准化 LLM 应用如何连接到不同的系统。从本质上讲：当你想为一个你不能控制的 agent 引入工具时，MCP 就会派上用场。在 MCP 出现之前，开发者必须编写代码，并通过 API 将 AI 工具与外部系统连接，这意味着每个集成都需要预先编码。MCP 的核心价值在于：让用户为不可控的 Agent 添加工具。例如在使用 Claude Desktop、Cursor 等应用时，普通用户无法修改底层 Agent 的代码，但通过 MCP 协议就能为其扩展新工具。非开发者通过 MCP 定制个性化 Agent 将成为可能。

![](/public/upload/machine/mcp.jpg)

从LLM的角度看，它标准化了应用程序如何为 LLM 提供上下文。LLM侧是比较清爽简单的，所有“变”和“不一样”的东西都放在这个MCP Server这里，类似于一个适配于LLM的Adapter。在此之上就是各种Agent工具，随着Agent和应用不断复杂，是一定需要单独抽一层这样的Adapter出来的。**相对于LLM应用直连外部资源，这里主要多了一个中间层（MCP Server），以及连接这个中间层的（MCP Client）**，理解了这两个，你就理解了MCP。

## mcp 协议

[协议specification](https://spec.modelcontextprotocol.io/specification/2025-03-26/) 

MCP（Model Context Protocol，模型上下文协议）旨在实现大型语言模型（LLM）与外部数据源和工具的无缝集成，目标是成为 AI 领域的“HTTP 协议”，推动 LLM 应用的标准化和去中心化。

client-host-server architecture。
1. Base Protocol: Core JSON-RPC message types
2. Lifecycle Management: Connection initialization, capability negotiation, and session control
3. Server Features: Resources, prompts, and tools exposed by servers
    
    2. 资源，表示 MCP 服务器想要向客户端提供的任何类型的数据。包括：文件内容、数据库记录、API 响应、实时系统数据、截图和图片、日志文件等更多内容。每个资源由唯一的 URI 标识，并且可以包含文本或二进制数据。
        ```js
        {
            uri: string;           // Unique identifier for the resource
            name: string;          // Human-readable name
            description?: string;  // Optional description
            mimeType?: string;     // Optional MIME type
        }
        ```
    3. 提示，是预定义的模板
        ```js
        {
            name: string;              // Unique identifier for the prompt
            description?: string;      // Human-readable description
            arguments?: [              // Optional list of arguments
                {
                name: string;          // Argument identifier
                description?: string;  // Argument description
                required?: boolean;    // Whether argument is required
                }
            ]
        }
        ```
    4. 工具，允许服务器公开可由客户端调用并由 LLM 用来执行操作的可执行函数。工具的关键方面包括：
        1. 发现 tools/list：客户端可以通过端点列出可用的工具
        2. 调用：使用端点调用工具 tools/call，服务器执行请求的操作并返回结果

        ```js
        {
            name: string;          // Unique identifier for the tool
            description?: string;  // Human-readable description
            inputSchema: {         // JSON Schema for the tool's parameters
                type: "object",
                properties: { ... }  // Tool-specific parameters
            }
        }
        ```
4. Client Features: Sampling and root directory lists provided by clients
5. Utilities: Cross-cutting concerns like logging and argument completion




## mcp server

MCP 服务器本质是通过 MCP 协议提供标准化接口的服务端。会将其功能公开为具有语义描述的“工具”。**每个工具都是自我描述的**，并包含有关工具功能、每个参数的含义、预期输出以及约束和限制的信息。假设你更改了服务器中某个工具所需的参数数量。使用 MCP，你不会破坏使用服务器的任何客户端。PS: 与api区别是多了一个 description 字段。这个字段是用来描述这个 API 的功能，以及如何使用的。以让其它 AI Agent 能够更好地调用。

MCP Server有哪些“服务”？

1. Tools：提供给LLM应用特别是Agent使用的工具。
2. Resoures：提供给LLM应用一些额外的结构化数据。**资源通常提供数据，而不是执行动作，与工具不同**。
3. Prompts：提供给LLM应用的一些Prompt模板。比如你的应用是一个Chatbot，可以从MCP Server中取出这些模板，让使用者选择使用。

MCP Server如何启动？
1. 本地模式下，在LLM应用中配置启动命令后，会自动启动MCP Server
2. 不同的MCP Server可能有不同的启动命令，注意查看MCP Server说明书
3. 有的MCP Server需要先安装依赖；有的通过npx/uvx运行的MCP server，则会自动下载缓存并临时运行。

[mcp server 列表](https://github.com/modelcontextprotocol/servers)

### 本地模式

本地模式下MCP Server可以部署在LLM应用本机
1. 在LLM应用中配置启动命令后，会自动启动MCP Server，MCP Server启动后的物理形式是一个独立的进程。
2. MCP Server与客户端应用间通过stdio/stdout（标准输入输出）的进程间通信进行消息交换。这种方式你肯定见过，比如：`cat file.txt | grep "error" | sort > result.txt`，还有类似k8s的cni 插件
3. 服务器再连接到互联网上的各种API和服务。

![](/public/upload/machine/mcp_local.jpg)

Local MCP Server虽然简单易用，但在企业级应用中面临诸多挑战：
1. 本地环境依赖，对用户本地环境有依赖，比如需要安装 python或docker 等执行环境来运行MCP Server，对非技术用户不友好
2. 安全风险，企业不可能将敏感数据库凭证、API密钥或其他关键访问令牌配置给每个员工的本地环境。这不仅违反最小权限原则，还大大增加了凭证泄露的风险。
3. 一致性问题，当多个用户需要访问相同的企业资源时，难以保证配置和权限的一致性，容易导致数据不一致或权限混乱。
4. 维护成本，为每个用户设备部署和维护MCP Server需要大量IT资源，版本更新、安全补丁和配置变更都需要在每台设备上单独执行。

### remote模式

Remote MCP Server则是部署在云端的MCP服务器，用户可以通过互联网访问。在这种模式下，MCP客户端可以是更广泛的网页应用或移动应用，它们通过HTTP协议与远程MCP服务器通信。Remote MCP Server通常集成了认证授权、状态管理、数据库访问等企业级功能，能够为多用户提供服务。

![](/public/upload/machine/mcp_remote.jpg)

## mcp client

MCP Client是由客户端LLM app使用Client SDK创建并维护的一个Server会话，就像你在程序中维护一个数据库的Connection一样。一般长这样：

```python
async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write, sampling_callback=None) as session:
        # 查看Server的Tools
        tools = await session.list_tools()
```
本地模式下，Client与Server是一对一的关系。如果需要连接多个MCP Server，需要自行维护多个Session

## 源码分析

### mcp server

```python
from mcp.server.fastmcp import FastMCP
# 初始化了一个 MCP 服务器对象，后续的功能将基于这个对象注册和运行
mcp = FastMCP("演示")

# 将 add 函数注册为 MCP 服务器的一个“工具”（Tool）
@mcp.tool()
def add(a:int, b:int)-> int:
    """
    Adds two numbers.
    """
    return a + b
# 定义一个资源函数 get_greeting
@mcp.resource("greeting://{name}")
def get_greeting(name:str)-> str:
    """
    Returns a greeting message.
    """
    return f"Hello, {name}!"
if __name__ == "__main__":
    # transport='stdio': 指定通信方式为标准输入输出（stdio）。这意味着服务器通过命令行（终端）的输入和输出与客户端通信，而不是通过网络（如 HTTP 或 WebSocket）。
    mcp.run(transport='stdio') # 调用 FastMCP 实例的 run 方法，开始运行服务器
```

## 其它

[8种主流Agent框架与MCP的集成](https://mp.weixin.qq.com/s/WGOnLFLAZhdvxu1qUs8Aww) 思路两种
1. 原生支持mcp，当然底层还是tool
2. 将mcp 视为tool

一些比较有意思的mcp [在 Kubernetes 和 AI 之间搭一座桥：MCP-K8s](https://mp.weixin.qq.com/s/cj85oqslbaXKP1xJ-aSqpQ)